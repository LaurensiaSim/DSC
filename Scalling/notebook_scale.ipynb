{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import all needed Libraries/Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read data, and then do some explanatory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DC024</th>\n",
       "      <th>DC025</th>\n",
       "      <th>DC205</th>\n",
       "      <th>DC220</th>\n",
       "      <th>DC226</th>\n",
       "      <th>DC230a</th>\n",
       "      <th>DC237</th>\n",
       "      <th>DC237a</th>\n",
       "      <th>DC237b</th>\n",
       "      <th>DC237f</th>\n",
       "      <th>DC241</th>\n",
       "      <th>DC244</th>\n",
       "      <th>DC246</th>\n",
       "      <th>DC109</th>\n",
       "      <th>DC201</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.322809</td>\n",
       "      <td>0.804467</td>\n",
       "      <td>-0.105158</td>\n",
       "      <td>2.434765</td>\n",
       "      <td>0.319398</td>\n",
       "      <td>-0.456516</td>\n",
       "      <td>0.512539</td>\n",
       "      <td>0.553102</td>\n",
       "      <td>-0.061283</td>\n",
       "      <td>-0.464013</td>\n",
       "      <td>-0.356393</td>\n",
       "      <td>-0.814230</td>\n",
       "      <td>-0.816532</td>\n",
       "      <td>-0.553274</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.322809</td>\n",
       "      <td>0.804467</td>\n",
       "      <td>1.959367</td>\n",
       "      <td>-0.342153</td>\n",
       "      <td>-0.373110</td>\n",
       "      <td>-0.456516</td>\n",
       "      <td>0.512539</td>\n",
       "      <td>0.553102</td>\n",
       "      <td>-0.061283</td>\n",
       "      <td>-0.464013</td>\n",
       "      <td>-0.356393</td>\n",
       "      <td>1.228154</td>\n",
       "      <td>1.224692</td>\n",
       "      <td>1.109705</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.322809</td>\n",
       "      <td>0.804467</td>\n",
       "      <td>-0.655698</td>\n",
       "      <td>-1.036383</td>\n",
       "      <td>-0.373110</td>\n",
       "      <td>-0.456516</td>\n",
       "      <td>0.512539</td>\n",
       "      <td>0.553102</td>\n",
       "      <td>-0.061283</td>\n",
       "      <td>-0.464013</td>\n",
       "      <td>-0.356393</td>\n",
       "      <td>1.228154</td>\n",
       "      <td>1.224692</td>\n",
       "      <td>-0.640799</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.322809</td>\n",
       "      <td>0.804467</td>\n",
       "      <td>-0.655698</td>\n",
       "      <td>2.357628</td>\n",
       "      <td>0.319398</td>\n",
       "      <td>-0.456516</td>\n",
       "      <td>0.512539</td>\n",
       "      <td>0.553102</td>\n",
       "      <td>-0.061283</td>\n",
       "      <td>-0.464013</td>\n",
       "      <td>2.132331</td>\n",
       "      <td>1.228154</td>\n",
       "      <td>-0.816532</td>\n",
       "      <td>-0.640799</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.322809</td>\n",
       "      <td>0.804467</td>\n",
       "      <td>-0.655698</td>\n",
       "      <td>-0.882110</td>\n",
       "      <td>0.319398</td>\n",
       "      <td>1.064267</td>\n",
       "      <td>0.512539</td>\n",
       "      <td>0.553102</td>\n",
       "      <td>-0.061283</td>\n",
       "      <td>-0.464013</td>\n",
       "      <td>-0.356393</td>\n",
       "      <td>-0.814230</td>\n",
       "      <td>1.224692</td>\n",
       "      <td>-0.640799</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64791</th>\n",
       "      <td>1.324220</td>\n",
       "      <td>0.804467</td>\n",
       "      <td>1.546462</td>\n",
       "      <td>1.586262</td>\n",
       "      <td>0.319398</td>\n",
       "      <td>1.064267</td>\n",
       "      <td>0.512539</td>\n",
       "      <td>0.553102</td>\n",
       "      <td>-0.061283</td>\n",
       "      <td>1.993716</td>\n",
       "      <td>-0.356393</td>\n",
       "      <td>1.228154</td>\n",
       "      <td>1.224692</td>\n",
       "      <td>0.934655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64792</th>\n",
       "      <td>1.120602</td>\n",
       "      <td>0.804467</td>\n",
       "      <td>-0.105158</td>\n",
       "      <td>-0.187880</td>\n",
       "      <td>-0.026856</td>\n",
       "      <td>-0.456516</td>\n",
       "      <td>0.512539</td>\n",
       "      <td>0.553102</td>\n",
       "      <td>-0.061283</td>\n",
       "      <td>-0.464013</td>\n",
       "      <td>-0.356393</td>\n",
       "      <td>-0.814230</td>\n",
       "      <td>-0.816532</td>\n",
       "      <td>-0.203173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64793</th>\n",
       "      <td>0.835538</td>\n",
       "      <td>0.804467</td>\n",
       "      <td>-0.518063</td>\n",
       "      <td>-0.650700</td>\n",
       "      <td>-0.373110</td>\n",
       "      <td>1.064267</td>\n",
       "      <td>0.512539</td>\n",
       "      <td>0.553102</td>\n",
       "      <td>-0.061283</td>\n",
       "      <td>-0.464013</td>\n",
       "      <td>-0.356393</td>\n",
       "      <td>1.228154</td>\n",
       "      <td>1.224692</td>\n",
       "      <td>-0.378223</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64794</th>\n",
       "      <td>-1.037744</td>\n",
       "      <td>0.804467</td>\n",
       "      <td>-0.105158</td>\n",
       "      <td>0.892033</td>\n",
       "      <td>0.319398</td>\n",
       "      <td>1.064267</td>\n",
       "      <td>0.512539</td>\n",
       "      <td>0.553102</td>\n",
       "      <td>-0.061283</td>\n",
       "      <td>-0.464013</td>\n",
       "      <td>-0.356393</td>\n",
       "      <td>-0.814230</td>\n",
       "      <td>-0.816532</td>\n",
       "      <td>0.146928</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64795</th>\n",
       "      <td>-1.241362</td>\n",
       "      <td>0.804467</td>\n",
       "      <td>-0.655698</td>\n",
       "      <td>0.043530</td>\n",
       "      <td>0.319398</td>\n",
       "      <td>-0.456516</td>\n",
       "      <td>0.512539</td>\n",
       "      <td>0.553102</td>\n",
       "      <td>-0.061283</td>\n",
       "      <td>-0.464013</td>\n",
       "      <td>2.132331</td>\n",
       "      <td>-0.814230</td>\n",
       "      <td>-0.816532</td>\n",
       "      <td>-0.640799</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64796 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DC024     DC025     DC205     DC220     DC226    DC230a     DC237   \n",
       "0     -1.322809  0.804467 -0.105158  2.434765  0.319398 -0.456516  0.512539  \\\n",
       "1     -1.322809  0.804467  1.959367 -0.342153 -0.373110 -0.456516  0.512539   \n",
       "2     -1.322809  0.804467 -0.655698 -1.036383 -0.373110 -0.456516  0.512539   \n",
       "3     -1.322809  0.804467 -0.655698  2.357628  0.319398 -0.456516  0.512539   \n",
       "4     -1.322809  0.804467 -0.655698 -0.882110  0.319398  1.064267  0.512539   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "64791  1.324220  0.804467  1.546462  1.586262  0.319398  1.064267  0.512539   \n",
       "64792  1.120602  0.804467 -0.105158 -0.187880 -0.026856 -0.456516  0.512539   \n",
       "64793  0.835538  0.804467 -0.518063 -0.650700 -0.373110  1.064267  0.512539   \n",
       "64794 -1.037744  0.804467 -0.105158  0.892033  0.319398  1.064267  0.512539   \n",
       "64795 -1.241362  0.804467 -0.655698  0.043530  0.319398 -0.456516  0.512539   \n",
       "\n",
       "         DC237a    DC237b    DC237f     DC241     DC244     DC246     DC109   \n",
       "0      0.553102 -0.061283 -0.464013 -0.356393 -0.814230 -0.816532 -0.553274  \\\n",
       "1      0.553102 -0.061283 -0.464013 -0.356393  1.228154  1.224692  1.109705   \n",
       "2      0.553102 -0.061283 -0.464013 -0.356393  1.228154  1.224692 -0.640799   \n",
       "3      0.553102 -0.061283 -0.464013  2.132331  1.228154 -0.816532 -0.640799   \n",
       "4      0.553102 -0.061283 -0.464013 -0.356393 -0.814230  1.224692 -0.640799   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "64791  0.553102 -0.061283  1.993716 -0.356393  1.228154  1.224692  0.934655   \n",
       "64792  0.553102 -0.061283 -0.464013 -0.356393 -0.814230 -0.816532 -0.203173   \n",
       "64793  0.553102 -0.061283 -0.464013 -0.356393  1.228154  1.224692 -0.378223   \n",
       "64794  0.553102 -0.061283 -0.464013 -0.356393 -0.814230 -0.816532  0.146928   \n",
       "64795  0.553102 -0.061283 -0.464013  2.132331 -0.814230 -0.816532 -0.640799   \n",
       "\n",
       "       DC201  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "64791      1  \n",
       "64792      1  \n",
       "64793      1  \n",
       "64794      1  \n",
       "64795      1  \n",
       "\n",
       "[64796 rows x 15 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('train_selected_scaled_round.csv',header=0,index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 64796 entries, 0 to 64795\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   DC024   64796 non-null  float64\n",
      " 1   DC025   64796 non-null  float64\n",
      " 2   DC205   64796 non-null  float64\n",
      " 3   DC220   64796 non-null  float64\n",
      " 4   DC226   64796 non-null  float64\n",
      " 5   DC230a  64796 non-null  float64\n",
      " 6   DC237   64796 non-null  float64\n",
      " 7   DC237a  64796 non-null  float64\n",
      " 8   DC237b  64796 non-null  float64\n",
      " 9   DC237f  64796 non-null  float64\n",
      " 10  DC241   64796 non-null  float64\n",
      " 11  DC244   64796 non-null  float64\n",
      " 12  DC246   64796 non-null  float64\n",
      " 13  DC109   64796 non-null  float64\n",
      " 14  DC201   64796 non-null  int64  \n",
      "dtypes: float64(14), int64(1)\n",
      "memory usage: 7.9 MB\n"
     ]
    }
   ],
   "source": [
    "# gather information about data attribute\n",
    "data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari data di atas, dapat dilihat bahwa semua data bertipe data flloat/integer, dan label bertipe data string."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cari informasi apakah ada data yang bernilai null/kosong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DC024     0\n",
       "DC025     0\n",
       "DC205     0\n",
       "DC220     0\n",
       "DC226     0\n",
       "DC230a    0\n",
       "DC237     0\n",
       "DC237a    0\n",
       "DC237b    0\n",
       "DC237f    0\n",
       "DC241     0\n",
       "DC244     0\n",
       "DC246     0\n",
       "DC109     0\n",
       "DC201     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DC201\n",
       "0    32398\n",
       "1    32398\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['DC201'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45357, 14)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split dataset menjadi training dan testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(data.drop('DC201',axis=1),data['DC201'],test_size=0.3)\n",
    "input_shape=(x_train.shape)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`input_shape` must be a tuple of three integers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n\u001b[1;32m----> 3\u001b[0m pretrained_model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39;49mapplications\u001b[39m.\u001b[39;49mDenseNet121(weights\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mimagenet\u001b[39;49m\u001b[39m'\u001b[39;49m, include_top\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, input_shape\u001b[39m=\u001b[39;49m(\u001b[39m19\u001b[39;49m, \u001b[39m1\u001b[39;49m))\n\u001b[0;32m      4\u001b[0m \u001b[39m# Membekukan semua lapisan pada model yang dilatih\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m pretrained_model\u001b[39m.\u001b[39mlayers:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\applications\\densenet.py:333\u001b[0m, in \u001b[0;36mDenseNet121\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39m@keras_export\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mkeras.applications.densenet.DenseNet121\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    325\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mkeras.applications.DenseNet121\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    326\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mDenseNet121\u001b[39m(include_top\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    330\u001b[0m                 pooling\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m                 classes\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m):\n\u001b[0;32m    332\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Instantiates the Densenet121 architecture.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 333\u001b[0m   \u001b[39mreturn\u001b[39;00m DenseNet([\u001b[39m6\u001b[39;49m, \u001b[39m12\u001b[39;49m, \u001b[39m24\u001b[39;49m, \u001b[39m16\u001b[39;49m], include_top, weights, input_tensor,\n\u001b[0;32m    334\u001b[0m                   input_shape, pooling, classes)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\applications\\densenet.py:210\u001b[0m, in \u001b[0;36mDenseNet\u001b[1;34m(blocks, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m    206\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mIf using `weights` as `\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimagenet\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m` with `include_top`\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    207\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m as true, `classes` should be 1000\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    209\u001b[0m \u001b[39m# Determine proper input shape\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m input_shape \u001b[39m=\u001b[39m imagenet_utils\u001b[39m.\u001b[39;49mobtain_input_shape(\n\u001b[0;32m    211\u001b[0m     input_shape,\n\u001b[0;32m    212\u001b[0m     default_size\u001b[39m=\u001b[39;49m\u001b[39m224\u001b[39;49m,\n\u001b[0;32m    213\u001b[0m     min_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[0;32m    214\u001b[0m     data_format\u001b[39m=\u001b[39;49mbackend\u001b[39m.\u001b[39;49mimage_data_format(),\n\u001b[0;32m    215\u001b[0m     require_flatten\u001b[39m=\u001b[39;49minclude_top,\n\u001b[0;32m    216\u001b[0m     weights\u001b[39m=\u001b[39;49mweights)\n\u001b[0;32m    218\u001b[0m \u001b[39mif\u001b[39;00m input_tensor \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    219\u001b[0m   img_input \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39minput_shape)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\applications\\imagenet_utils.py:370\u001b[0m, in \u001b[0;36mobtain_input_shape\u001b[1;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[39mif\u001b[39;00m input_shape \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(input_shape) \u001b[39m!=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m--> 370\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`input_shape` must be a tuple of three integers.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    371\u001b[0m   \u001b[39mif\u001b[39;00m input_shape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m weights \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mimagenet\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    372\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mThe input must have 3 channels; Received \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    373\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m`input_shape=\u001b[39m\u001b[39m{\u001b[39;00minput_shape\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: `input_shape` must be a tuple of three integers."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "pretrained_model = keras.applications.DenseNet121(weights='imagenet', include_top=False, input_shape=(19, 1))\n",
    "# Membekukan semua lapisan pada model yang dilatih\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False\n",
    "model = keras.Sequential([\n",
    "    pretrained_model,\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Kompilasi model dengan optimizer, loss function, dan metrics\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 36, 32)            128       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 34, 32)            3104      \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 32, 32)            3104      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 32)            0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 16, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               51300     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,393\n",
      "Trainable params: 320,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32,kernel_size=3,input_shape=(38,1),activation='relu'),\n",
    "    tf.keras.layers.Conv1D(filters=32,kernel_size=3,activation='relu'),\n",
    "    tf.keras.layers.Conv1D(filters=32,kernel_size=3,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.MaxPool1D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512,activation='relu'),\n",
    "    tf.keras.layers.Dense(100,activation='relu'),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',f1_m])\n",
    "\n",
    "# Print the model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "One of the dimensions in the output is <= 0 due to downsampling in conv1d_7. Consider increasing the input size. Received input shape [None, 1, 128] which would produce output shape with a zero or negative value in a dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m input_shape \u001b[39m=\u001b[39m (\u001b[39m11\u001b[39m, \u001b[39m1\u001b[39m)  \u001b[39m# 38 attributes, 1 feature\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m# Define the model architecture\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m model\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mSequential([\n\u001b[0;32m      9\u001b[0m     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mConv1D(filters\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,kernel_size\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,input_shape\u001b[39m=\u001b[39;49m(\u001b[39m19\u001b[39;49m,\u001b[39m1\u001b[39;49m),activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[0;32m     10\u001b[0m     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mConv1D(filters\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,kernel_size\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[0;32m     11\u001b[0m     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mMaxPool1D(\u001b[39m2\u001b[39;49m,\u001b[39m2\u001b[39;49m),\n\u001b[0;32m     12\u001b[0m     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mDropout(\u001b[39m0.25\u001b[39;49m),\n\u001b[0;32m     13\u001b[0m     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mConv1D(filters\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m,kernel_size\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[0;32m     14\u001b[0m     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mConv1D(filters\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m,kernel_size\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[0;32m     15\u001b[0m     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mMaxPool1D(\u001b[39m2\u001b[39;49m,\u001b[39m2\u001b[39;49m),\n\u001b[0;32m     16\u001b[0m     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mDropout(\u001b[39m0.25\u001b[39;49m),\n\u001b[0;32m     17\u001b[0m     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mConv1D(filters\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m,kernel_size\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[0;32m     18\u001b[0m     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mConv1D(filters\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m,kernel_size\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[0;32m     19\u001b[0m     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mMaxPool1D(\u001b[39m2\u001b[39;49m,\u001b[39m2\u001b[39;49m),\n\u001b[0;32m     20\u001b[0m     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mDropout(\u001b[39m0.25\u001b[39;49m),\n\u001b[0;32m     21\u001b[0m     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mFlatten(),\n\u001b[0;32m     22\u001b[0m     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mDense(\u001b[39m512\u001b[39;49m,activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[0;32m     23\u001b[0m     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mDropout(\u001b[39m0.5\u001b[39;49m),\n\u001b[0;32m     24\u001b[0m     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mDense(\u001b[39m1\u001b[39;49m,activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msigmoid\u001b[39;49m\u001b[39m'\u001b[39;49m)])\n\u001b[0;32m     26\u001b[0m \u001b[39m# Compile the model\u001b[39;00m\n\u001b[0;32m     27\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m,f1_m])\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:530\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 530\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    531\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\layers\\convolutional.py:302\u001b[0m, in \u001b[0;36mConv.compute_output_shape\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mTensorShape(\n\u001b[0;32m    298\u001b[0m         input_shape[:batch_rank] \u001b[39m+\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilters] \u001b[39m+\u001b[39m\n\u001b[0;32m    299\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_spatial_output_shape(input_shape[batch_rank \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m:]))\n\u001b[0;32m    301\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m--> 302\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    303\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mOne of the dimensions in the output is <= 0 \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    304\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdue to downsampling in \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m. Consider \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    305\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mincreasing the input size. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    306\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mReceived input shape \u001b[39m\u001b[39m{\u001b[39;00minput_shape\u001b[39m}\u001b[39;00m\u001b[39m which would produce \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    307\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39moutput shape with a zero or negative value in a \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    308\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdimension.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in conv1d_7. Consider increasing the input size. Received input shape [None, 1, 128] which would produce output shape with a zero or negative value in a dimension."
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (11, 1)  # 38 attributes, 1 feature\n",
    "\n",
    "# Define the model architecture\n",
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=64,kernel_size=3,input_shape=(19,1),activation='relu'),\n",
    "    tf.keras.layers.Conv1D(filters=64,kernel_size=3,activation='relu'),\n",
    "    tf.keras.layers.MaxPool1D(2,2),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Conv1D(filters=128,kernel_size=3,activation='relu'),\n",
    "    tf.keras.layers.Conv1D(filters=128,kernel_size=3,activation='relu'),\n",
    "    tf.keras.layers.MaxPool1D(2,2),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Conv1D(filters=256,kernel_size=3,activation='relu'),\n",
    "    tf.keras.layers.Conv1D(filters=256,kernel_size=3,activation='relu'),\n",
    "    tf.keras.layers.MaxPool1D(2,2),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',f1_m])\n",
    "\n",
    "# Print the model summary\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 38, 1), found shape=(None, 19)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mfit(x_train,y_train,epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1129\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1129\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   1130\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1131\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 38, 1), found shape=(None, 19)\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,epochs=10,batch_size=32,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608/608 [==============================] - 3s 4ms/step - loss: 0.1621 - accuracy: 0.9300 - f1_m: 0.9257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1621331423521042, 0.9300375580787659, 0.9256654977798462]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Menampilkan grafik akurasi\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.plot(history.history['val_'+metric], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.title(f'Grafik {metric}')\n",
    "  plt.legend([metric, 'val_'+metric])\n",
    "  \n",
    "plot_graphs(history,'f1_m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.3.5-py3-none-win_amd64.whl (1.0 MB)\n",
      "                                              0.0/1.0 MB ? eta -:--:--\n",
      "     ---                                      0.1/1.0 MB 2.3 MB/s eta 0:00:01\n",
      "     -----                                    0.1/1.0 MB 2.1 MB/s eta 0:00:01\n",
      "     -----                                    0.1/1.0 MB 2.1 MB/s eta 0:00:01\n",
      "     -----                                    0.1/1.0 MB 2.1 MB/s eta 0:00:01\n",
      "     -----                                    0.1/1.0 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------                          0.4/1.0 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------                    0.6/1.0 MB 1.8 MB/s eta 0:00:01\n",
      "     ---------------------------------        0.8/1.0 MB 2.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.0/1.0 MB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel in c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from lightgbm) (0.40.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from lightgbm) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from lightgbm) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from lightgbm) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.5\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = svm.SVC(verbose=True)\n",
    "clf.fit(x_train, y_train)\n",
    "# melakukan prediksi menggunakan data testing\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "# menghitung akurasi\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1=f1_score(y_test, y_pred)\n",
    "print('Accuracy:', acc, 'F1 Score ',f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8344565049642472 F1 Score  0.835849826566007\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Define Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Train model\n",
    "gb_model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = gb_model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1=f1_score(y_test, y_pred)\n",
    "print('Accuracy:', acc, 'F1 Score ',f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300, 'subsample': 0.9}\n",
      "Best Score:  0.949511603250625\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load your data and split it into features and labels\n",
    "X = x_train# Your feature matrix\n",
    "y = y_train  # Your target labels\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Create an XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# Perform grid search using cross-validation\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit the grid search to your data\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8794176655177736 F1 Score  0.8797208538587848\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "# define xgboost model\n",
    "model = xgb.XGBClassifier(learning_rate=0.1,max_depth=6,n_estimators=300,subsample=0.9,colsample_bytree=0.8)\n",
    "\n",
    "# fit the model on the training set\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1=f1_score(y_test, y_pred)\n",
    "print('Accuracy:', acc, 'F1 Score ',f1)\n",
    "model.save_model(\"xgboost_model_6.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8792118936159268 F1 Score  0.8792926177256838\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "# define xgboost model\n",
    "model = xgb.XGBClassifier(learning_rate=0.1,max_depth=7,n_estimators=300,subsample=0.7,colsample_bytree=0.5)\n",
    "\n",
    "# fit the model on the training set\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1=f1_score(y_test, y_pred)\n",
    "print('Accuracy:', acc, 'F1 Score ',f1)\n",
    "model.save_model(\"xgboost_model_6.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'colsample_bytree': 0.7, 'learning_rate': 0.3, 'max_depth': 7, 'n_estimators': 300, 'subsample': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.882607129996399 F1 Score  0.8826976457283849\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "\n",
    "# define xgboost model\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "# define hyperparameter grid for grid search\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.5, 0.7],\n",
    "    'colsample_bytree': [0.5, 0.7],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "}\n",
    "\n",
    "# perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='accuracy', n_jobs=-1, cv=5)\n",
    "grid_result = grid_search.fit(x_train, y_train)\n",
    "\n",
    "# print the best hyperparameters\n",
    "print(\"Best parameters: \", grid_result.best_params_)\n",
    "\n",
    "# create a new model with the best hyperparameters\n",
    "model = xgb.XGBClassifier(**grid_result.best_params_)\n",
    "\n",
    "# fit the model on the training set\n",
    "model.fit(x_train, y_train, early_stopping_rounds=10, eval_metric='logloss', eval_set=[(x_test, y_test)], verbose=False)\n",
    "\n",
    "# make predi your target price\n",
    "# ctions on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# calculate accuracy of predictions\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1=f1_score(y_test, y_pred)\n",
    "print('Accuracy:', acc, 'F1 Score ',f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost 10CV GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300, 'subsample': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9478368228818355 F1 Score  0.9460810379666064\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "\n",
    "# define xgboost model\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "# define hyperparameter grid for grid search\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.5, 0.7],\n",
    "    'colsample_bytree': [0.5, 0.7],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "}\n",
    "\n",
    "# perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='accuracy', n_jobs=-1, cv=10)\n",
    "grid_result = grid_search.fit(x_train, y_train)\n",
    "\n",
    "# print the best hyperparameters\n",
    "print(\"Best parameters: \", grid_result.best_params_)\n",
    "\n",
    "# create a new model with the best hyperparameters\n",
    "model = xgb.XGBClassifier(**grid_result.best_params_)\n",
    "\n",
    "# fit the model on the training set\n",
    "model.fit(x_train, y_train, early_stopping_rounds=10, eval_metric='logloss', eval_set=[(x_test, y_test)], verbose=False)\n",
    "\n",
    "# make predi your target price\n",
    "# ctions on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# calculate accuracy of predictions\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1=f1_score(y_test, y_pred)\n",
    "print('Accuracy:', acc, 'F1 Score ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"xgboost_model_7.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# define the AdaBoost model\n",
    "model = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "# fit the model on the training set\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# calculate accuracy of predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
